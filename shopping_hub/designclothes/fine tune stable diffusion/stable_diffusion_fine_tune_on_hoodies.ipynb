{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune Stable Diffusion"
      ],
      "metadata": {
        "id": "sWHOC0uvLigk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change to content directory\n",
        "!cd /content/\n",
        "# clone huggingface diffuseres repositury from github\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "!pip install ./diffusers\n",
        "# installing requirements for diffuers\n",
        "!pip install -U -r /content/diffusers/examples/text_to_image/requirements.txt"
      ],
      "metadata": {
        "id": "Qvpguj7hLtbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cheking the gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "mMxiv4GvMCAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default --mixed_precision fp16"
      ],
      "metadata": {
        "id": "_nHEqtR2MIht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### directory to save model after training"
      ],
      "metadata": {
        "id": "6NhoavusNKTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 3 stable diffusion model\n",
        "os.environ['MODEL_NAME'] = f'CompVis/stable-diffusion-v1-2'\n",
        "# dataset\n",
        "os.environ['DATASET_NAME'] = f'choudharyprince890/martin_valen_hoodies'\n",
        "# directory to save model\n",
        "os.environ['OUTPUT_DIR'] = f'sd_martin_valen-model-v1-2_400'"
      ],
      "metadata": {
        "id": "iv4ezc0eM1D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "add token for authentication"
      ],
      "metadata": {
        "id": "bzhzg8-oNw7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "l3ypSfHgNGj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model parameters"
      ],
      "metadata": {
        "id": "WAJ2SoRvOCW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/README.md"
      ],
      "metadata": {
        "id": "dZbx7i6zTyHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --dataset_name=$DATASET_NAME \\\n",
        "  --use_ema \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=400 \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --push_to_hub \\\n",
        "  --checkpointing_steps=100000 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --output_dir=$OUTPUT_DIR"
      ],
      "metadata": {
        "id": "lSn8sfImN7EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stable Diffusion V1\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "model_path = \"./sd_martin_valen-model-v1-2_400_demo\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# Run inference using ChatGPT prompts to acquire 4 image panels\n",
        "image1 = pipe(prompt=\"black hoodie with a front half zipper by martin valen\").images[0]\n",
        "image1.save(\"ProductSnapAI_panel_1.png\")\n",
        "\n",
        "image2 = pipe(prompt=\"white hoodie with a blue design by martin valen\").images[0]\n",
        "image2.save(\"ProductSnapAI_panel_2.png\")\n",
        "\n",
        "image3 = pipe(prompt=\"stripped hoodie by martin valen\").images[0]\n",
        "image3.save(\"ProductSnapAI_panel_3.png\")\n",
        "\n",
        "image4 = pipe(prompt=\"camouflage hoodie by martin valen\").images[0]\n",
        "image4.save(\"ProductSnapAI_panel_4.png\")\n",
        "\n",
        "# Image grid helper function from HuggingFace\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "all_images = [image1, image2, image3, image4]\n",
        "grid = image_grid(all_images, rows=1, cols=4)\n",
        "grid"
      ],
      "metadata": {
        "id": "QsYNKP7pOHvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}